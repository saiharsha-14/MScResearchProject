{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98890d27-b610-4ff5-9a7f-6b977879e124",
   "metadata": {},
   "source": [
    "### **Data Gathering, Cleaning and Preprocessing for Tesla and Apple Stocks**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84389579-969a-4dae-b9de-09143d88617f",
   "metadata": {},
   "source": [
    "#### This notebook gathers and preprocesses data from Reddit, GDELT news articles, and Yahoo Finance for Tesla (TSLA) and Apple (AAPL) from 2018 to 2024, preparing it for sentiment analysis and predictive modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a1fab0-9f07-4305-abbf-e625c20aa67e",
   "metadata": {},
   "source": [
    "#### Installing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffe4f0a3-0a9e-4904-8970-1d70a0777a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: praw in c:\\users\\harsh\\anaconda3\\lib\\site-packages (7.7.1)\n",
      "Requirement already satisfied: yfinance in c:\\users\\harsh\\anaconda3\\lib\\site-packages (0.2.40)\n",
      "Requirement already satisfied: prawcore<3,>=2.1 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from praw) (2.4.0)\n",
      "Requirement already satisfied: update-checker>=0.18 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from praw) (0.18.0)\n",
      "Requirement already satisfied: websocket-client>=0.54.0 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from praw) (1.8.0)\n",
      "Requirement already satisfied: pandas>=1.3.0 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from yfinance) (2.0.3)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from yfinance) (1.24.3)\n",
      "Requirement already satisfied: requests>=2.31 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from yfinance) (2.31.0)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from yfinance) (0.0.11)\n",
      "Requirement already satisfied: lxml>=4.9.1 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from yfinance) (4.9.3)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from yfinance) (3.10.0)\n",
      "Requirement already satisfied: pytz>=2022.5 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from yfinance) (2023.3.post1)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from yfinance) (2.4.4)\n",
      "Requirement already satisfied: peewee>=3.16.2 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from yfinance) (3.17.5)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from yfinance) (4.12.2)\n",
      "Requirement already satisfied: html5lib>=1.1 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from yfinance) (1.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.5)\n",
      "Requirement already satisfied: six>=1.9 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from html5lib>=1.1->yfinance) (1.16.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from pandas>=1.3.0->yfinance) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from requests>=2.31->yfinance) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from requests>=2.31->yfinance) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from requests>=2.31->yfinance) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from requests>=2.31->yfinance) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install praw yfinance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfb095e-650d-441d-9274-6b68ccb7c1ab",
   "metadata": {},
   "source": [
    "#### Imporing Required Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf7d18d9-873f-4610-814f-2f884b698c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import yfinance as yf\n",
    "import praw\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197ce122-ae19-4ca8-b15f-cff5c8788e92",
   "metadata": {},
   "source": [
    "#### Ensure that you provide the correct file paths for posts.csv, stock_index.csv, and wallstreetbets_2022.csv datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71d7dde7-d7a2-446c-a45e-715d9e235f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_fp = r\"D:\\ire\\Sem_3\\research_computing\\stock_index.csv\"\n",
    "ids_df = pd.read_csv(ids_fp)\n",
    "\n",
    "posts_fp= r\"D:\\ire\\Sem_3\\research_computing\\posts.csv\"\n",
    "reddit_df =  pd.read_csv(posts_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64a1b2c9-0f53-4208-a3b6-a44d9d320d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filtered_reddit_data(ticker, reddit_df, ids_df):\n",
    "    try:\n",
    "        # Filter ids_df for the specified stock ticker\n",
    "        ticker_ids_df = ids_df[ids_df['stock_symbol'].str.lower() == ticker.lower()]\n",
    "        \n",
    "        # Merge with reddit_df to get only matching records\n",
    "        ticker_reddit_df = reddit_df.merge(ticker_ids_df, on='id', how='inner')\n",
    "        \n",
    "        # Select relevant columns\n",
    "        filtered_stock_reddit_df = ticker_reddit_df[['title', 'created_utc_x', 'selftext', 'subreddit']]\n",
    "        \n",
    "        # Convert 'created_utc_x' to datetime and rename it\n",
    "        filtered_stock_reddit_df['created_utc'] = pd.to_datetime(\n",
    "            filtered_stock_reddit_df['created_utc_x'], unit='s', errors='coerce'\n",
    "        )\n",
    "        \n",
    "        # Define date range for filtering\n",
    "        start_date = pd.to_datetime('2018-01-01')\n",
    "        end_date = pd.to_datetime('2023-01-01')\n",
    "        \n",
    "        # Filter by date range\n",
    "        filtered_reddit_data = filtered_stock_reddit_df[\n",
    "            (filtered_stock_reddit_df['created_utc'] >= start_date) &\n",
    "            (filtered_stock_reddit_df['created_utc'] <= end_date)\n",
    "        ]\n",
    "        \n",
    "        # Drop unnecessary column\n",
    "        filtered_reddit_data.drop('created_utc_x', axis=1, inplace=True)\n",
    "        return filtered_reddit_data\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "        return pd.DataFrame()  # Return an empty DataFrame in case of error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8995a8f-def2-4b97-b5f6-e5add15484c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\AppData\\Local\\Temp\\ipykernel_14524\\366657704.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_stock_reddit_df['created_utc'] = pd.to_datetime(\n",
      "C:\\Users\\harsh\\AppData\\Local\\Temp\\ipykernel_14524\\366657704.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_stock_reddit_df['created_utc'] = pd.to_datetime(\n"
     ]
    }
   ],
   "source": [
    "tsla_reddit_18_22 = get_filtered_reddit_data(\"tsla\", reddit_df, ids_df)\n",
    "aapl_reddit_18_22 = get_filtered_reddit_data(\"aapl\", reddit_df, ids_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "774b5cce-f344-4afc-8529-913250b5d35c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bi-weekly TSLA Investor Thread</td>\n",
       "      <td>This will post every other Monday (EST) at 6AM...</td>\n",
       "      <td>teslamotors</td>\n",
       "      <td>2018-01-01 11:14:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Long $TSLA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>2018-01-01 18:44:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Get ready to short $TSLA - they finally added ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>2018-01-01 20:41:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>stocks</td>\n",
       "      <td>2018-01-01 21:04:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Quick 1/1/18 drive-by looks like Marina Del Re...</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>teslamotors</td>\n",
       "      <td>2018-01-01 23:52:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73267</th>\n",
       "      <td>$TSLA Awaiting Short Signal based off 9 signal...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>StockTradingIdeas</td>\n",
       "      <td>2022-12-31 21:13:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73268</th>\n",
       "      <td>2022 Performance and Lessons</td>\n",
       "      <td>Doing this in post form so I can include scree...</td>\n",
       "      <td>u_SpiritBearBC</td>\n",
       "      <td>2022-12-31 21:45:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73269</th>\n",
       "      <td>2022 Berry Bad Bear year in review</td>\n",
       "      <td>Tough year for many, myself included. My tradi...</td>\n",
       "      <td>options</td>\n",
       "      <td>2022-12-31 22:53:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73270</th>\n",
       "      <td>LEADERBOARD: Sat, Dec 31, 2022: 06:16 PM EST</td>\n",
       "      <td>#TOP TRADERS  \\n  ##Overall\\nRanking | Name | ...</td>\n",
       "      <td>InsiderMemeTrading</td>\n",
       "      <td>2022-12-31 23:16:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73271</th>\n",
       "      <td>Today's most mentioned tickers</td>\n",
       "      <td>## The following are the top 10 most mentioned...</td>\n",
       "      <td>u_WSBTickercountBOT</td>\n",
       "      <td>2022-12-31 23:50:18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73272 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "0                         Bi-weekly TSLA Investor Thread   \n",
       "1                                             Long $TSLA   \n",
       "2      Get ready to short $TSLA - they finally added ...   \n",
       "3                                                   TSLA   \n",
       "4      Quick 1/1/18 drive-by looks like Marina Del Re...   \n",
       "...                                                  ...   \n",
       "73267  $TSLA Awaiting Short Signal based off 9 signal...   \n",
       "73268                       2022 Performance and Lessons   \n",
       "73269                 2022 Berry Bad Bear year in review   \n",
       "73270       LEADERBOARD: Sat, Dec 31, 2022: 06:16 PM EST   \n",
       "73271                     Today's most mentioned tickers   \n",
       "\n",
       "                                                selftext            subreddit  \\\n",
       "0      This will post every other Monday (EST) at 6AM...          teslamotors   \n",
       "1                                                    NaN       wallstreetbets   \n",
       "2                                                    NaN       wallstreetbets   \n",
       "3                                              [removed]               stocks   \n",
       "4                                              [deleted]          teslamotors   \n",
       "...                                                  ...                  ...   \n",
       "73267                                                NaN    StockTradingIdeas   \n",
       "73268  Doing this in post form so I can include scree...       u_SpiritBearBC   \n",
       "73269  Tough year for many, myself included. My tradi...              options   \n",
       "73270  #TOP TRADERS  \\n  ##Overall\\nRanking | Name | ...   InsiderMemeTrading   \n",
       "73271  ## The following are the top 10 most mentioned...  u_WSBTickercountBOT   \n",
       "\n",
       "              created_utc  \n",
       "0     2018-01-01 11:14:30  \n",
       "1     2018-01-01 18:44:21  \n",
       "2     2018-01-01 20:41:06  \n",
       "3     2018-01-01 21:04:17  \n",
       "4     2018-01-01 23:52:28  \n",
       "...                   ...  \n",
       "73267 2022-12-31 21:13:49  \n",
       "73268 2022-12-31 21:45:57  \n",
       "73269 2022-12-31 22:53:13  \n",
       "73270 2022-12-31 23:16:31  \n",
       "73271 2022-12-31 23:50:18  \n",
       "\n",
       "[73272 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsla_reddit_18_22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ac6bd02-8ea5-43fd-80b6-208e24934692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blowing versus sucking</td>\n",
       "      <td>AAPL just entered a contract to purchase 51 of...</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>2018-01-01 01:04:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The 2018 /r/Robinhood Stock Picking Game</td>\n",
       "      <td># tl;dr\\n\\n - Stock picking game will last all...</td>\n",
       "      <td>RobinHood</td>\n",
       "      <td>2018-01-01 16:37:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hesitant to invest in $AAPL</td>\n",
       "      <td>Looking at AAPLs fundamentals and the pile of ...</td>\n",
       "      <td>investing</td>\n",
       "      <td>2018-01-01 20:21:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stock mix help required (ETF)</td>\n",
       "      <td>I’ve decided I’m most likely interested in jus...</td>\n",
       "      <td>stocks</td>\n",
       "      <td>2018-01-01 21:54:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ETF advice please!</td>\n",
       "      <td>I’ve decided I’m most likely interested in jus...</td>\n",
       "      <td>personalfinance</td>\n",
       "      <td>2018-01-01 22:12:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39301</th>\n",
       "      <td>$AAPL Awaiting Buy Signal based off 9 signals ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>StockTradingIdeas</td>\n",
       "      <td>2022-12-31 21:03:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39302</th>\n",
       "      <td>2022 Performance and Lessons</td>\n",
       "      <td>Doing this in post form so I can include scree...</td>\n",
       "      <td>u_SpiritBearBC</td>\n",
       "      <td>2022-12-31 21:45:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39303</th>\n",
       "      <td>2022 Berry Bad Bear year in review</td>\n",
       "      <td>Tough year for many, myself included. My tradi...</td>\n",
       "      <td>options</td>\n",
       "      <td>2022-12-31 22:53:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39304</th>\n",
       "      <td>Today's most mentioned tickers</td>\n",
       "      <td>## The following are the top 10 most mentioned...</td>\n",
       "      <td>u_WSBTickercountBOT</td>\n",
       "      <td>2022-12-31 23:50:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39305</th>\n",
       "      <td>Anyone completed AAPL or ACHE courses and tran...</td>\n",
       "      <td>I’ve been toying with getting an MBA and looki...</td>\n",
       "      <td>medicine</td>\n",
       "      <td>2022-12-31 23:51:58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39306 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "0                                 Blowing versus sucking   \n",
       "1               The 2018 /r/Robinhood Stock Picking Game   \n",
       "2                            Hesitant to invest in $AAPL   \n",
       "3                          Stock mix help required (ETF)   \n",
       "4                                     ETF advice please!   \n",
       "...                                                  ...   \n",
       "39301  $AAPL Awaiting Buy Signal based off 9 signals ...   \n",
       "39302                       2022 Performance and Lessons   \n",
       "39303                 2022 Berry Bad Bear year in review   \n",
       "39304                     Today's most mentioned tickers   \n",
       "39305  Anyone completed AAPL or ACHE courses and tran...   \n",
       "\n",
       "                                                selftext            subreddit  \\\n",
       "0      AAPL just entered a contract to purchase 51 of...       wallstreetbets   \n",
       "1      # tl;dr\\n\\n - Stock picking game will last all...            RobinHood   \n",
       "2      Looking at AAPLs fundamentals and the pile of ...            investing   \n",
       "3      I’ve decided I’m most likely interested in jus...               stocks   \n",
       "4      I’ve decided I’m most likely interested in jus...      personalfinance   \n",
       "...                                                  ...                  ...   \n",
       "39301                                                NaN    StockTradingIdeas   \n",
       "39302  Doing this in post form so I can include scree...       u_SpiritBearBC   \n",
       "39303  Tough year for many, myself included. My tradi...              options   \n",
       "39304  ## The following are the top 10 most mentioned...  u_WSBTickercountBOT   \n",
       "39305  I’ve been toying with getting an MBA and looki...             medicine   \n",
       "\n",
       "              created_utc  \n",
       "0     2018-01-01 01:04:25  \n",
       "1     2018-01-01 16:37:41  \n",
       "2     2018-01-01 20:21:33  \n",
       "3     2018-01-01 21:54:14  \n",
       "4     2018-01-01 22:12:01  \n",
       "...                   ...  \n",
       "39301 2022-12-31 21:03:43  \n",
       "39302 2022-12-31 21:45:57  \n",
       "39303 2022-12-31 22:53:13  \n",
       "39304 2022-12-31 23:50:18  \n",
       "39305 2022-12-31 23:51:58  \n",
       "\n",
       "[39306 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aapl_reddit_18_22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3df933-c611-4b50-9e05-6d8db07afa92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "99642e05-bf31-4674-b70d-5400c76f7efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\AppData\\Local\\Temp\\ipykernel_14524\\3202706487.py:2: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  wallstreetbets_df = pd.read_csv(wallstreetbets_fp)\n"
     ]
    }
   ],
   "source": [
    "wallstreetbets_fp = r\"D:\\ire\\Sem_3\\research_computing\\wallstreetbets_2022.csv\"\n",
    "wallstreetbets_df = pd.read_csv(wallstreetbets_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "80460188-1b26-4412-bf54-fa569719087a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filtered_reddit_23_24(df, keywords):\n",
    "    # Convert timestamp column to datetime if it isn't already\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')\n",
    "    \n",
    "    # Define the start date for filtering\n",
    "    start_date = \"2023-01-01\"\n",
    "    \n",
    "    # Filter rows based on keywords in the body column and timestamp after the start date\n",
    "    reddit_data = df[\n",
    "        (df['body'].str.contains('|'.join(keywords), case=False, na=False)) &\n",
    "        (df['timestamp'] >= start_date)]\n",
    "    return reddit_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7146a8e8-52f8-4424-8363-8e679b0a7b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define keywords for filtering\n",
    "tsla_keywords = [\"tesla stocks\", \"tsla\", \"tesla stock market\", \"tesla\", \"tesla finance\", \"tesla stock price\", \"tsla clsoing price\"]\n",
    "aapl_keywords = [\"apple stocks\", \"aapl\", \"apple stock market\", \"apple\", \"apple finance\", \"apple stock price\", \"aapl clsoing price\"]\n",
    "tsla_reddit_23_24 = get_filtered_reddit_23_24(wallstreetbets_df, tsla_keywords)\n",
    "aapl_reddit_23_24 = get_filtered_reddit_23_24(wallstreetbets_df, aapl_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "14724459-49da-4b48-8da7-2301274e525c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>comms_num</th>\n",
       "      <th>created</th>\n",
       "      <th>body</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>290353</th>\n",
       "      <td>Comment</td>\n",
       "      <td>1</td>\n",
       "      <td>j2gkuq7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.672542e+09</td>\n",
       "      <td>Bag holder at 33 and 38 (two puts assigned), b...</td>\n",
       "      <td>2023-01-01 03:02:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290384</th>\n",
       "      <td>Comment</td>\n",
       "      <td>1</td>\n",
       "      <td>j2gkbft</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.672542e+09</td>\n",
       "      <td>#Ban Bet Lost\\n\\n/u/_theshortbig made a bet th...</td>\n",
       "      <td>2023-01-01 02:57:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290461</th>\n",
       "      <td>Comment</td>\n",
       "      <td>1</td>\n",
       "      <td>j2gjf6e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.672541e+09</td>\n",
       "      <td>You're right. I'm wrong. Investors definitely ...</td>\n",
       "      <td>2023-01-01 02:49:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290471</th>\n",
       "      <td>Comment</td>\n",
       "      <td>1</td>\n",
       "      <td>j2gjb0w</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.672541e+09</td>\n",
       "      <td>good points. I'm not saying that they should h...</td>\n",
       "      <td>2023-01-01 02:48:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290509</th>\n",
       "      <td>Comment</td>\n",
       "      <td>4</td>\n",
       "      <td>j2giwpr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.672541e+09</td>\n",
       "      <td>Tesla 200 end of march?</td>\n",
       "      <td>2023-01-01 02:45:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985277</th>\n",
       "      <td>Those who think removing the EV tax credit wil...</td>\n",
       "      <td>7133</td>\n",
       "      <td>1grqiw1</td>\n",
       "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>861.0</td>\n",
       "      <td>1.731653e+09</td>\n",
       "      <td>1. Trump removes $7,500 EV tax credits and imp...</td>\n",
       "      <td>2024-11-15 06:49:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985285</th>\n",
       "      <td>Coping with Loss in the Time of 🥭 (TSLA and LUNR)</td>\n",
       "      <td>278</td>\n",
       "      <td>1grk58c</td>\n",
       "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>177.0</td>\n",
       "      <td>1.731632e+09</td>\n",
       "      <td>https://preview.redd.it/tk91sh5tpy0e1.jpg?widt...</td>\n",
       "      <td>2024-11-15 00:49:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985297</th>\n",
       "      <td>South Korea's \"Value Up\" program, and why Kore...</td>\n",
       "      <td>123</td>\n",
       "      <td>1grc49j</td>\n",
       "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1.731610e+09</td>\n",
       "      <td>Korean stocks have long been undervalued, refe...</td>\n",
       "      <td>2024-11-14 18:51:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985777</th>\n",
       "      <td>Comment</td>\n",
       "      <td>2</td>\n",
       "      <td>lzsjz62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.733011e+09</td>\n",
       "      <td>Open the fucking markets my Tesla calls are re...</td>\n",
       "      <td>2024-11-30 23:58:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985942</th>\n",
       "      <td>Comment</td>\n",
       "      <td>2</td>\n",
       "      <td>lzsgmef</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.733010e+09</td>\n",
       "      <td>FSD V13 rolling out to customers - TSLA gap up...</td>\n",
       "      <td>2024-11-30 23:38:29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10469 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    title score       id  \\\n",
       "290353                                            Comment     1  j2gkuq7   \n",
       "290384                                            Comment     1  j2gkbft   \n",
       "290461                                            Comment     1  j2gjf6e   \n",
       "290471                                            Comment     1  j2gjb0w   \n",
       "290509                                            Comment     4  j2giwpr   \n",
       "...                                                   ...   ...      ...   \n",
       "985277  Those who think removing the EV tax credit wil...  7133  1grqiw1   \n",
       "985285  Coping with Loss in the Time of 🥭 (TSLA and LUNR)   278  1grk58c   \n",
       "985297  South Korea's \"Value Up\" program, and why Kore...   123  1grc49j   \n",
       "985777                                            Comment     2  lzsjz62   \n",
       "985942                                            Comment     2  lzsgmef   \n",
       "\n",
       "                                                      url  comms_num  \\\n",
       "290353                                                NaN        0.0   \n",
       "290384                                                NaN        0.0   \n",
       "290461                                                NaN        0.0   \n",
       "290471                                                NaN        0.0   \n",
       "290509                                                NaN        0.0   \n",
       "...                                                   ...        ...   \n",
       "985277  https://www.reddit.com/r/wallstreetbets/commen...      861.0   \n",
       "985285  https://www.reddit.com/r/wallstreetbets/commen...      177.0   \n",
       "985297  https://www.reddit.com/r/wallstreetbets/commen...       96.0   \n",
       "985777                                                NaN        0.0   \n",
       "985942                                                NaN        0.0   \n",
       "\n",
       "             created                                               body  \\\n",
       "290353  1.672542e+09  Bag holder at 33 and 38 (two puts assigned), b...   \n",
       "290384  1.672542e+09  #Ban Bet Lost\\n\\n/u/_theshortbig made a bet th...   \n",
       "290461  1.672541e+09  You're right. I'm wrong. Investors definitely ...   \n",
       "290471  1.672541e+09  good points. I'm not saying that they should h...   \n",
       "290509  1.672541e+09                            Tesla 200 end of march?   \n",
       "...              ...                                                ...   \n",
       "985277  1.731653e+09  1. Trump removes $7,500 EV tax credits and imp...   \n",
       "985285  1.731632e+09  https://preview.redd.it/tk91sh5tpy0e1.jpg?widt...   \n",
       "985297  1.731610e+09  Korean stocks have long been undervalued, refe...   \n",
       "985777  1.733011e+09  Open the fucking markets my Tesla calls are re...   \n",
       "985942  1.733010e+09  FSD V13 rolling out to customers - TSLA gap up...   \n",
       "\n",
       "                 timestamp  \n",
       "290353 2023-01-01 03:02:31  \n",
       "290384 2023-01-01 02:57:44  \n",
       "290461 2023-01-01 02:49:58  \n",
       "290471 2023-01-01 02:48:58  \n",
       "290509 2023-01-01 02:45:32  \n",
       "...                    ...  \n",
       "985277 2024-11-15 06:49:43  \n",
       "985285 2024-11-15 00:49:00  \n",
       "985297 2024-11-14 18:51:15  \n",
       "985777 2024-11-30 23:58:49  \n",
       "985942 2024-11-30 23:38:29  \n",
       "\n",
       "[10469 rows x 8 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsla_reddit_23_24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6dcca72a-5fb6-4325-9fd5-3b05670b7474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>comms_num</th>\n",
       "      <th>created</th>\n",
       "      <th>body</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>290425</th>\n",
       "      <td>Comment</td>\n",
       "      <td>1</td>\n",
       "      <td>j2gjs2h</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.672542e+09</td>\n",
       "      <td>I made 100k on Amazon and lost it all. So I’m ...</td>\n",
       "      <td>2023-01-01 02:53:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290439</th>\n",
       "      <td>Comment</td>\n",
       "      <td>1</td>\n",
       "      <td>j2gjn90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.672542e+09</td>\n",
       "      <td>Apple UIs are specifically designed for regard...</td>\n",
       "      <td>2023-01-01 02:51:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290969</th>\n",
       "      <td>Comment</td>\n",
       "      <td>1</td>\n",
       "      <td>j2ge5co</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.672539e+09</td>\n",
       "      <td>Consumers have a short memory. And Musk is fic...</td>\n",
       "      <td>2023-01-01 02:06:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291084</th>\n",
       "      <td>Comment</td>\n",
       "      <td>2</td>\n",
       "      <td>j2gd4xp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.672538e+09</td>\n",
       "      <td>Woah that Apple commercial was something special</td>\n",
       "      <td>2023-01-01 01:58:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291199</th>\n",
       "      <td>Comment</td>\n",
       "      <td>0</td>\n",
       "      <td>j2gc6ko</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.672538e+09</td>\n",
       "      <td>People are always so impressed when i rip an a...</td>\n",
       "      <td>2023-01-01 01:50:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985002</th>\n",
       "      <td>2 month rollercoaster: 2k&gt;55k &gt; -25k &gt; 125k</td>\n",
       "      <td>84</td>\n",
       "      <td>1gwj01d</td>\n",
       "      <td>https://www.reddit.com/gallery/1gwj01d</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.732206e+09</td>\n",
       "      <td>After not trading for a 2 years to save up for...</td>\n",
       "      <td>2024-11-21 16:15:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985062</th>\n",
       "      <td>$ACHR The Bull Run Hasn't Started Yet</td>\n",
       "      <td>2339</td>\n",
       "      <td>1gvrgv6</td>\n",
       "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>498.0</td>\n",
       "      <td>1.732115e+09</td>\n",
       "      <td>**TLDR:** Current fair value is +$10imo, Arch...</td>\n",
       "      <td>2024-11-20 15:02:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985173</th>\n",
       "      <td>Trump taps big tech critic Carr to lead US com...</td>\n",
       "      <td>794</td>\n",
       "      <td>1gu78hv</td>\n",
       "      <td>https://www.yahoo.com/news/trump-taps-big-tech...</td>\n",
       "      <td>141.0</td>\n",
       "      <td>1.731944e+09</td>\n",
       "      <td>How do you think MSFT, META, GOOGL, and AAPL w...</td>\n",
       "      <td>2024-11-18 15:26:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985321</th>\n",
       "      <td>SoundHound AI Stock Tumbles as Margins Drop</td>\n",
       "      <td>21</td>\n",
       "      <td>1gqnmrh</td>\n",
       "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.731532e+09</td>\n",
       "      <td>Was looking more into earnings and what could ...</td>\n",
       "      <td>2024-11-13 21:08:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985904</th>\n",
       "      <td>Comment</td>\n",
       "      <td>1</td>\n",
       "      <td>lzshkxm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.733010e+09</td>\n",
       "      <td>#MOTHER FOCKA WE GO TO DAGESTAN RIGHT NOW AMD ...</td>\n",
       "      <td>2024-11-30 23:44:17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5314 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    title score       id  \\\n",
       "290425                                            Comment     1  j2gjs2h   \n",
       "290439                                            Comment     1  j2gjn90   \n",
       "290969                                            Comment     1  j2ge5co   \n",
       "291084                                            Comment     2  j2gd4xp   \n",
       "291199                                            Comment     0  j2gc6ko   \n",
       "...                                                   ...   ...      ...   \n",
       "985002       2 month rollercoaster: 2k>55k > -25k > 125k     84  1gwj01d   \n",
       "985062              $ACHR The Bull Run Hasn't Started Yet  2339  1gvrgv6   \n",
       "985173  Trump taps big tech critic Carr to lead US com...   794  1gu78hv   \n",
       "985321       SoundHound AI Stock Tumbles as Margins Drop     21  1gqnmrh   \n",
       "985904                                            Comment     1  lzshkxm   \n",
       "\n",
       "                                                      url  comms_num  \\\n",
       "290425                                                NaN        0.0   \n",
       "290439                                                NaN        0.0   \n",
       "290969                                                NaN        0.0   \n",
       "291084                                                NaN        0.0   \n",
       "291199                                                NaN        0.0   \n",
       "...                                                   ...        ...   \n",
       "985002             https://www.reddit.com/gallery/1gwj01d       21.0   \n",
       "985062  https://www.reddit.com/r/wallstreetbets/commen...      498.0   \n",
       "985173  https://www.yahoo.com/news/trump-taps-big-tech...      141.0   \n",
       "985321  https://www.reddit.com/r/wallstreetbets/commen...       15.0   \n",
       "985904                                                NaN        0.0   \n",
       "\n",
       "             created                                               body  \\\n",
       "290425  1.672542e+09  I made 100k on Amazon and lost it all. So I’m ...   \n",
       "290439  1.672542e+09  Apple UIs are specifically designed for regard...   \n",
       "290969  1.672539e+09  Consumers have a short memory. And Musk is fic...   \n",
       "291084  1.672538e+09   Woah that Apple commercial was something special   \n",
       "291199  1.672538e+09  People are always so impressed when i rip an a...   \n",
       "...              ...                                                ...   \n",
       "985002  1.732206e+09  After not trading for a 2 years to save up for...   \n",
       "985062  1.732115e+09   **TLDR:** Current fair value is +$10imo, Arch...   \n",
       "985173  1.731944e+09  How do you think MSFT, META, GOOGL, and AAPL w...   \n",
       "985321  1.731532e+09  Was looking more into earnings and what could ...   \n",
       "985904  1.733010e+09  #MOTHER FOCKA WE GO TO DAGESTAN RIGHT NOW AMD ...   \n",
       "\n",
       "                 timestamp  \n",
       "290425 2023-01-01 02:53:05  \n",
       "290439 2023-01-01 02:51:55  \n",
       "290969 2023-01-01 02:06:35  \n",
       "291084 2023-01-01 01:58:27  \n",
       "291199 2023-01-01 01:50:49  \n",
       "...                    ...  \n",
       "985002 2024-11-21 16:15:48  \n",
       "985062 2024-11-20 15:02:27  \n",
       "985173 2024-11-18 15:26:03  \n",
       "985321 2024-11-13 21:08:42  \n",
       "985904 2024-11-30 23:44:17  \n",
       "\n",
       "[5314 rows x 8 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aapl_reddit_23_24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22758440-7b59-4fe3-ab85-bfbc2836fc3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aa5cc189-af76-486f-90dd-f18162695f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize columns in tsla_reddit_23_24\n",
    "tsla_reddit_23_24 = tsla_reddit_23_24.rename(columns={'body': 'selftext', 'timestamp': 'created_utc'})\n",
    "\n",
    "# Keep only the necessary columns\n",
    "tsla_reddit_18_22 = tsla_reddit_18_22[['title', 'selftext', 'created_utc']]\n",
    "tsla_reddit_23_24 = tsla_reddit_23_24[['title', 'selftext', 'created_utc']]\n",
    "\n",
    "# Concatenate the two DataFrames\n",
    "tsla_reddit_data_18_to_24 = pd.concat([tsla_reddit_18_22, tsla_reddit_23_24], ignore_index=True)\n",
    "\n",
    "# Convert 'created_utc' to datetime format\n",
    "tsla_reddit_data_18_to_24['created_utc'] = pd.to_datetime(tsla_reddit_data_18_to_24['created_utc'])\n",
    "\n",
    "# Fill missing selftext with empty strings\n",
    "tsla_reddit_data_18_to_24['selftext'] = tsla_reddit_data_18_to_24['selftext'].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ab79ad34-080e-4475-b8be-7359064e653a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>created_utc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bi-weekly TSLA Investor Thread</td>\n",
       "      <td>This will post every other Monday (EST) at 6AM...</td>\n",
       "      <td>2018-01-01 11:14:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Long $TSLA</td>\n",
       "      <td></td>\n",
       "      <td>2018-01-01 18:44:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Get ready to short $TSLA - they finally added ...</td>\n",
       "      <td></td>\n",
       "      <td>2018-01-01 20:41:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>2018-01-01 21:04:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Quick 1/1/18 drive-by looks like Marina Del Re...</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>2018-01-01 23:52:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83736</th>\n",
       "      <td>Those who think removing the EV tax credit wil...</td>\n",
       "      <td>1. Trump removes $7,500 EV tax credits and imp...</td>\n",
       "      <td>2024-11-15 06:49:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83737</th>\n",
       "      <td>Coping with Loss in the Time of 🥭 (TSLA and LUNR)</td>\n",
       "      <td>https://preview.redd.it/tk91sh5tpy0e1.jpg?widt...</td>\n",
       "      <td>2024-11-15 00:49:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83738</th>\n",
       "      <td>South Korea's \"Value Up\" program, and why Kore...</td>\n",
       "      <td>Korean stocks have long been undervalued, refe...</td>\n",
       "      <td>2024-11-14 18:51:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83739</th>\n",
       "      <td>Comment</td>\n",
       "      <td>Open the fucking markets my Tesla calls are re...</td>\n",
       "      <td>2024-11-30 23:58:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83740</th>\n",
       "      <td>Comment</td>\n",
       "      <td>FSD V13 rolling out to customers - TSLA gap up...</td>\n",
       "      <td>2024-11-30 23:38:29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83741 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "0                         Bi-weekly TSLA Investor Thread   \n",
       "1                                             Long $TSLA   \n",
       "2      Get ready to short $TSLA - they finally added ...   \n",
       "3                                                   TSLA   \n",
       "4      Quick 1/1/18 drive-by looks like Marina Del Re...   \n",
       "...                                                  ...   \n",
       "83736  Those who think removing the EV tax credit wil...   \n",
       "83737  Coping with Loss in the Time of 🥭 (TSLA and LUNR)   \n",
       "83738  South Korea's \"Value Up\" program, and why Kore...   \n",
       "83739                                            Comment   \n",
       "83740                                            Comment   \n",
       "\n",
       "                                                selftext         created_utc  \n",
       "0      This will post every other Monday (EST) at 6AM... 2018-01-01 11:14:30  \n",
       "1                                                        2018-01-01 18:44:21  \n",
       "2                                                        2018-01-01 20:41:06  \n",
       "3                                              [removed] 2018-01-01 21:04:17  \n",
       "4                                              [deleted] 2018-01-01 23:52:28  \n",
       "...                                                  ...                 ...  \n",
       "83736  1. Trump removes $7,500 EV tax credits and imp... 2024-11-15 06:49:43  \n",
       "83737  https://preview.redd.it/tk91sh5tpy0e1.jpg?widt... 2024-11-15 00:49:00  \n",
       "83738  Korean stocks have long been undervalued, refe... 2024-11-14 18:51:15  \n",
       "83739  Open the fucking markets my Tesla calls are re... 2024-11-30 23:58:49  \n",
       "83740  FSD V13 rolling out to customers - TSLA gap up... 2024-11-30 23:38:29  \n",
       "\n",
       "[83741 rows x 3 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsla_reddit_data_18_to_24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0af1b342-15b9-4eed-855d-5613fe6d607a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize columns in aapl_reddit_23_24\n",
    "aapl_reddit_23_24 = aapl_reddit_23_24.rename(columns={'body': 'selftext', 'timestamp': 'created_utc'})\n",
    "\n",
    "# Keep only the necessary columns\n",
    "aapl_reddit_18_22 = aapl_reddit_18_22[['title', 'selftext', 'created_utc']]\n",
    "aapl_reddit_23_24 = aapl_reddit_23_24[['title', 'selftext', 'created_utc']]\n",
    "\n",
    "# Concatenate the two DataFrames\n",
    "aapl_reddit_data_18_to_24 = pd.concat([aapl_reddit_18_22, aapl_reddit_23_24], ignore_index=True)\n",
    "\n",
    "# Convert 'created_utc' to datetime format\n",
    "aapl_reddit_data_18_to_24['created_utc'] = pd.to_datetime(aapl_reddit_data_18_to_24['created_utc'])\n",
    "\n",
    "# Fill missing selftext with empty strings\n",
    "aapl_reddit_data_18_to_24['selftext'] = aapl_reddit_data_18_to_24['selftext'].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "892acba0-9f68-4809-8609-f46fe7549a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>created_utc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blowing versus sucking</td>\n",
       "      <td>AAPL just entered a contract to purchase 51 of...</td>\n",
       "      <td>2018-01-01 01:04:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The 2018 /r/Robinhood Stock Picking Game</td>\n",
       "      <td># tl;dr\\n\\n - Stock picking game will last all...</td>\n",
       "      <td>2018-01-01 16:37:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hesitant to invest in $AAPL</td>\n",
       "      <td>Looking at AAPLs fundamentals and the pile of ...</td>\n",
       "      <td>2018-01-01 20:21:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stock mix help required (ETF)</td>\n",
       "      <td>I’ve decided I’m most likely interested in jus...</td>\n",
       "      <td>2018-01-01 21:54:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ETF advice please!</td>\n",
       "      <td>I’ve decided I’m most likely interested in jus...</td>\n",
       "      <td>2018-01-01 22:12:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44615</th>\n",
       "      <td>2 month rollercoaster: 2k&gt;55k &gt; -25k &gt; 125k</td>\n",
       "      <td>After not trading for a 2 years to save up for...</td>\n",
       "      <td>2024-11-21 16:15:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44616</th>\n",
       "      <td>$ACHR The Bull Run Hasn't Started Yet</td>\n",
       "      <td>**TLDR:** Current fair value is +$10imo, Arch...</td>\n",
       "      <td>2024-11-20 15:02:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44617</th>\n",
       "      <td>Trump taps big tech critic Carr to lead US com...</td>\n",
       "      <td>How do you think MSFT, META, GOOGL, and AAPL w...</td>\n",
       "      <td>2024-11-18 15:26:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44618</th>\n",
       "      <td>SoundHound AI Stock Tumbles as Margins Drop</td>\n",
       "      <td>Was looking more into earnings and what could ...</td>\n",
       "      <td>2024-11-13 21:08:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44619</th>\n",
       "      <td>Comment</td>\n",
       "      <td>#MOTHER FOCKA WE GO TO DAGESTAN RIGHT NOW AMD ...</td>\n",
       "      <td>2024-11-30 23:44:17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44620 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "0                                 Blowing versus sucking   \n",
       "1               The 2018 /r/Robinhood Stock Picking Game   \n",
       "2                            Hesitant to invest in $AAPL   \n",
       "3                          Stock mix help required (ETF)   \n",
       "4                                     ETF advice please!   \n",
       "...                                                  ...   \n",
       "44615       2 month rollercoaster: 2k>55k > -25k > 125k    \n",
       "44616              $ACHR The Bull Run Hasn't Started Yet   \n",
       "44617  Trump taps big tech critic Carr to lead US com...   \n",
       "44618       SoundHound AI Stock Tumbles as Margins Drop    \n",
       "44619                                            Comment   \n",
       "\n",
       "                                                selftext         created_utc  \n",
       "0      AAPL just entered a contract to purchase 51 of... 2018-01-01 01:04:25  \n",
       "1      # tl;dr\\n\\n - Stock picking game will last all... 2018-01-01 16:37:41  \n",
       "2      Looking at AAPLs fundamentals and the pile of ... 2018-01-01 20:21:33  \n",
       "3      I’ve decided I’m most likely interested in jus... 2018-01-01 21:54:14  \n",
       "4      I’ve decided I’m most likely interested in jus... 2018-01-01 22:12:01  \n",
       "...                                                  ...                 ...  \n",
       "44615  After not trading for a 2 years to save up for... 2024-11-21 16:15:48  \n",
       "44616   **TLDR:** Current fair value is +$10imo, Arch... 2024-11-20 15:02:27  \n",
       "44617  How do you think MSFT, META, GOOGL, and AAPL w... 2024-11-18 15:26:03  \n",
       "44618  Was looking more into earnings and what could ... 2024-11-13 21:08:42  \n",
       "44619  #MOTHER FOCKA WE GO TO DAGESTAN RIGHT NOW AMD ... 2024-11-30 23:44:17  \n",
       "\n",
       "[44620 rows x 3 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aapl_reddit_data_18_to_24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefe7c31-baf8-4e86-a296-e29e36971044",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dfd9281a-822c-490a-a47f-31d3782d9422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data from 2018-01-01 00:00:00 to 2024-12-01 00:00:00 is done.\n"
     ]
    }
   ],
   "source": [
    "# Base GDELT API URL\n",
    "gdelt_api_url = \"https://api.gdeltproject.org/api/v2/doc/doc\"\n",
    "\n",
    "# Function to fetch data from GDELT for a specific date range\n",
    "def fetch_tsla_gdelt_data(start_date, end_date):\n",
    "    \n",
    "    params = {\n",
    "        \"query\": \"($Tsla OR Tesla OR Tesla stocks OR Tesla market OR Tesla shares OR Tesla trading OR Tesla finance OR Tesla investment OR Tesla Nasdaq OR Tesla performance)\",\n",
    "        \"mode\": \"artlist\",\n",
    "        \"maxrecords\": \"250\",  # Max records per query\n",
    "        \"format\": \"json\",\n",
    "        \"startdatetime\": start_date.strftime('%Y%m%d%H%M%S'),\n",
    "        \"enddatetime\": end_date.strftime('%Y%m%d%H%M%S'),\n",
    "    }\n",
    "    response = requests.get(gdelt_api_url, params=params)\n",
    "\n",
    "    # Check if the response was successful\n",
    "    if response.status_code == 200:\n",
    "        try:\n",
    "            data = response.json()\n",
    "            articles = data.get('articles', [])\n",
    "            return articles\n",
    "        except ValueError as e:\n",
    "            print(f\"JSON decode error for {start_date} to {end_date}: {e}\")\n",
    "            return []\n",
    "    else:\n",
    "        print(f\"Request failed for {start_date} to {end_date} with status code {response.status_code}\")\n",
    "        return []\n",
    "\n",
    "# Date range to iterate over\n",
    "start_date = datetime(2018, 1, 1)\n",
    "end_date = datetime(2024, 12, 1)\n",
    "\n",
    "# Initialize an empty list to store all the articles\n",
    "all_articles = []\n",
    "\n",
    "# Fetch data in batches of 30 days\n",
    "batch_size = 30\n",
    "current_start_date = start_date\n",
    "\n",
    "while current_start_date < end_date:\n",
    "    current_end_date = current_start_date + timedelta(days=batch_size)\n",
    "    if current_end_date > end_date:\n",
    "        current_end_date = end_date\n",
    "\n",
    "    # Fetch articles for the current date range\n",
    "    articles = fetch_tsla_gdelt_data(current_start_date, current_end_date)\n",
    "    all_articles.extend(articles)\n",
    "\n",
    "    # Move to the next date range\n",
    "    current_start_date = current_end_date\n",
    "\n",
    "# Convert the list of all articles into a DataFrame\n",
    "tsla_news_data = pd.DataFrame(all_articles)\n",
    "print(f\"Fetching data from {start_date} to {end_date} is done.\")\n",
    "\n",
    "# Filter and keep only relevant columns if data is available\n",
    "if not tsla_news_data.empty:\n",
    "    tsla_news_data = tsla_news_data[['url', 'seendate', 'title', 'domain']]\n",
    "else:\n",
    "    print(\"No data fetched.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4186d062-eeb8-4d5c-b0b9-30d05e187496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON decode error for 2019-12-22 00:00:00 to 2020-01-21 00:00:00: Invalid \\X escape sequence '\\\\': line 1 column 79382 (char 79381)\n",
      "Fetching data from 2018-01-01 00:00:00 to 2024-12-01 00:00:00 is done.\n"
     ]
    }
   ],
   "source": [
    "# Function to fetch data from GDELT for a specific date range\n",
    "def fetch_apple_gdelt_data(start_date, end_date):\n",
    "    params = {\n",
    "        \"query\": \"($AAPL OR Apple OR Apple stocks OR Apple market OR Apple shares OR Apple trading OR Apple finance OR Apple investment OR Apple Nasdaq OR Apple performance)\",\n",
    "        \"mode\": \"artlist\",\n",
    "        \"maxrecords\": \"250\",  # Max records per query\n",
    "        \"format\": \"json\",\n",
    "        \"startdatetime\": start_date.strftime('%Y%m%d%H%M%S'),\n",
    "        \"enddatetime\": end_date.strftime('%Y%m%d%H%M%S'),\n",
    "    }\n",
    "    response = requests.get(gdelt_api_url, params=params)\n",
    "\n",
    "    # Check if the response was successful\n",
    "    if response.status_code == 200:\n",
    "        try:\n",
    "            data = response.json()\n",
    "            articles = data.get('articles', [])\n",
    "            return articles\n",
    "        except ValueError as e:\n",
    "            print(f\"JSON decode error for {start_date} to {end_date}: {e}\")\n",
    "            return []\n",
    "    else:\n",
    "        print(f\"Request failed for {start_date} to {end_date} with status code {response.status_code}\")\n",
    "        return []\n",
    "\n",
    "# Date range to iterate over\n",
    "start_date = datetime(2018, 1, 1)\n",
    "end_date = datetime(2024, 12, 1)\n",
    "\n",
    "# Initialize an empty list to store all the articles\n",
    "all_articles = []\n",
    "\n",
    "# Fetch data in batches of 30 days\n",
    "batch_size = 30\n",
    "current_start_date = start_date\n",
    "\n",
    "while current_start_date < end_date:\n",
    "    current_end_date = current_start_date + timedelta(days=batch_size)\n",
    "    if current_end_date > end_date:\n",
    "        current_end_date = end_date\n",
    "\n",
    "    # Fetch articles for the current date range\n",
    "    articles = fetch_apple_gdelt_data(current_start_date, current_end_date)\n",
    "    all_articles.extend(articles)\n",
    "\n",
    "    # Move to the next date range\n",
    "    current_start_date = current_end_date\n",
    "\n",
    "# Convert the list of all articles into a DataFrame\n",
    "apple_news_data = pd.DataFrame(all_articles)\n",
    "print(f\"Fetching data from {start_date} to {end_date} is done.\")\n",
    "\n",
    "# Filter and keep only relevant columns if data is available\n",
    "if not apple_news_data.empty:\n",
    "    apple_news_data = apple_news_data[['url', 'seendate', 'title', 'domain']]\n",
    "else:\n",
    "    print(\"No data fetched.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a91019c6-950c-4fcf-a97e-c4f59f55d2de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>seendate</th>\n",
       "      <th>title</th>\n",
       "      <th>domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://kldaily.com/tesla-inc-tsla-eps-estimat...</td>\n",
       "      <td>20180129T074500Z</td>\n",
       "      <td>Tesla , Inc . ( TSLA ) EPS Estimated At $ - 3 ...</td>\n",
       "      <td>kldaily.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://friscofastball.com/analysts-see-3-75-e...</td>\n",
       "      <td>20180129T011500Z</td>\n",
       "      <td>Analysts See $ - 3 . 75 EPS for Tesla , Inc . ...</td>\n",
       "      <td>friscofastball.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.benchmarkmonitor.com/cnbc-a-key-eng...</td>\n",
       "      <td>20180130T111500Z</td>\n",
       "      <td>CNBC ; A  key Engineer  at Tesla Motors Inc ( ...</td>\n",
       "      <td>benchmarkmonitor.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://santimes.com/cousins-properties-cuz-an...</td>\n",
       "      <td>20180115T161500Z</td>\n",
       "      <td>Cousins Properties ( CUZ ) Analysts See $0 . 1...</td>\n",
       "      <td>santimes.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://ledgergazette.com/2018/01/19/insider-s...</td>\n",
       "      <td>20180119T063000Z</td>\n",
       "      <td>Tesla Inc ( NASDAQ : TSLA ) VP John Douglas Fi...</td>\n",
       "      <td>ledgergazette.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21245</th>\n",
       "      <td>http://www.itbear.com.cn/html/2024-11/609574.html</td>\n",
       "      <td>20241125T140000Z</td>\n",
       "      <td>特斯拉中国罕见优惠 ： Model Y最高减10000元 ！- 智能汽车 - ITBear科技资讯</td>\n",
       "      <td>itbear.com.cn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21246</th>\n",
       "      <td>https://www.ideastream.org/2024-11-22/tesla-wo...</td>\n",
       "      <td>20241125T041500Z</td>\n",
       "      <td>Tesla won the plug war . Enter the age of the ...</td>\n",
       "      <td>ideastream.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21247</th>\n",
       "      <td>https://www.cnet.com/paid-content/news/complet...</td>\n",
       "      <td>20241125T163000Z</td>\n",
       "      <td>Complete Your Home Energy Ecosystem With Tesla...</td>\n",
       "      <td>cnet.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21248</th>\n",
       "      <td>https://finance.sina.com.cn/jjxw/2024-11-30/do...</td>\n",
       "      <td>20241130T093000Z</td>\n",
       "      <td>极越汽车被指抄袭特斯拉 ？ CEO夏一平 ： 只是自动驾驶理念相同</td>\n",
       "      <td>finance.sina.com.cn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21249</th>\n",
       "      <td>https://www.standard.net.au/story/8829503/tesl...</td>\n",
       "      <td>20241125T093000Z</td>\n",
       "      <td>Tesla Model 3 ranked least reliable EV in used...</td>\n",
       "      <td>standard.net.au</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21250 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     url          seendate  \\\n",
       "0      https://kldaily.com/tesla-inc-tsla-eps-estimat...  20180129T074500Z   \n",
       "1      https://friscofastball.com/analysts-see-3-75-e...  20180129T011500Z   \n",
       "2      http://www.benchmarkmonitor.com/cnbc-a-key-eng...  20180130T111500Z   \n",
       "3      https://santimes.com/cousins-properties-cuz-an...  20180115T161500Z   \n",
       "4      https://ledgergazette.com/2018/01/19/insider-s...  20180119T063000Z   \n",
       "...                                                  ...               ...   \n",
       "21245  http://www.itbear.com.cn/html/2024-11/609574.html  20241125T140000Z   \n",
       "21246  https://www.ideastream.org/2024-11-22/tesla-wo...  20241125T041500Z   \n",
       "21247  https://www.cnet.com/paid-content/news/complet...  20241125T163000Z   \n",
       "21248  https://finance.sina.com.cn/jjxw/2024-11-30/do...  20241130T093000Z   \n",
       "21249  https://www.standard.net.au/story/8829503/tesl...  20241125T093000Z   \n",
       "\n",
       "                                                   title                domain  \n",
       "0      Tesla , Inc . ( TSLA ) EPS Estimated At $ - 3 ...           kldaily.com  \n",
       "1      Analysts See $ - 3 . 75 EPS for Tesla , Inc . ...    friscofastball.com  \n",
       "2      CNBC ; A  key Engineer  at Tesla Motors Inc ( ...  benchmarkmonitor.com  \n",
       "3      Cousins Properties ( CUZ ) Analysts See $0 . 1...          santimes.com  \n",
       "4      Tesla Inc ( NASDAQ : TSLA ) VP John Douglas Fi...     ledgergazette.com  \n",
       "...                                                  ...                   ...  \n",
       "21245  特斯拉中国罕见优惠 ： Model Y最高减10000元 ！- 智能汽车 - ITBear科技资讯         itbear.com.cn  \n",
       "21246  Tesla won the plug war . Enter the age of the ...        ideastream.org  \n",
       "21247  Complete Your Home Energy Ecosystem With Tesla...              cnet.com  \n",
       "21248                  极越汽车被指抄袭特斯拉 ？ CEO夏一平 ： 只是自动驾驶理念相同   finance.sina.com.cn  \n",
       "21249  Tesla Model 3 ranked least reliable EV in used...       standard.net.au  \n",
       "\n",
       "[21250 rows x 4 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsla_news_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "60d02fc4-ba50-40bc-aca5-59dccc5f05a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>seendate</th>\n",
       "      <th>title</th>\n",
       "      <th>domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://weeklyregister.com/british-columbia-inv...</td>\n",
       "      <td>20180121T120000Z</td>\n",
       "      <td>British Columbia Investment Management Corp Cu...</td>\n",
       "      <td>weeklyregister.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://bzweekly.com/2018/01/13/can-apple-inc-...</td>\n",
       "      <td>20180114T013000Z</td>\n",
       "      <td>Can Apple Inc . ( AAPL ) s Tomorrow be Differe...</td>\n",
       "      <td>bzweekly.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://kldaily.com/could-apple-inc-aapl-chang...</td>\n",
       "      <td>20180117T211500Z</td>\n",
       "      <td>Could Apple Inc . ( AAPL ) Change Direction Af...</td>\n",
       "      <td>kldaily.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://friscofastball.com/eaton-vance-managem...</td>\n",
       "      <td>20180120T131500Z</td>\n",
       "      <td>Eaton Vance Management Has Trimmed Position in...</td>\n",
       "      <td>friscofastball.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://finnewsdaily.com/as-apple-inc-aapl-stoc...</td>\n",
       "      <td>20180120T133000Z</td>\n",
       "      <td>As Apple INC ( AAPL ) Stock Price Rose , Share...</td>\n",
       "      <td>finnewsdaily.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20995</th>\n",
       "      <td>https://telegrafi.com/en/apple-zgjeron-kampanj...</td>\n",
       "      <td>20241125T060000Z</td>\n",
       "      <td>Apple expands  There more in an iPhone  campai...</td>\n",
       "      <td>telegrafi.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20996</th>\n",
       "      <td>http://kr.xinhuanet.com/20241127/f8f050da74194...</td>\n",
       "      <td>20241127T071500Z</td>\n",
       "      <td>팀 쿡 애플 CEO  中 , 세계에서 가장 중요한 공급사슬 - Xinhua</td>\n",
       "      <td>kr.xinhuanet.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20997</th>\n",
       "      <td>https://www.annapurnapost.com/story/469101/</td>\n",
       "      <td>20241126T164500Z</td>\n",
       "      <td>मुस्ताङको कृषि उत्पादनमा पर्यटकको क्रेज</td>\n",
       "      <td>annapurnapost.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20998</th>\n",
       "      <td>https://www.macworld.com/article/2535956/the-i...</td>\n",
       "      <td>20241127T201500Z</td>\n",
       "      <td>The next iPhone SE will be a study in sacrifice</td>\n",
       "      <td>macworld.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20999</th>\n",
       "      <td>https://www.chubun.com/modules/article/view.ar...</td>\n",
       "      <td>20241130T093000Z</td>\n",
       "      <td>中文导报网 - 导报新闻 - 苹果总裁库克 年内第三次访华</td>\n",
       "      <td>chubun.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     url          seendate  \\\n",
       "0      http://weeklyregister.com/british-columbia-inv...  20180121T120000Z   \n",
       "1      https://bzweekly.com/2018/01/13/can-apple-inc-...  20180114T013000Z   \n",
       "2      https://kldaily.com/could-apple-inc-aapl-chang...  20180117T211500Z   \n",
       "3      https://friscofastball.com/eaton-vance-managem...  20180120T131500Z   \n",
       "4      http://finnewsdaily.com/as-apple-inc-aapl-stoc...  20180120T133000Z   \n",
       "...                                                  ...               ...   \n",
       "20995  https://telegrafi.com/en/apple-zgjeron-kampanj...  20241125T060000Z   \n",
       "20996  http://kr.xinhuanet.com/20241127/f8f050da74194...  20241127T071500Z   \n",
       "20997        https://www.annapurnapost.com/story/469101/  20241126T164500Z   \n",
       "20998  https://www.macworld.com/article/2535956/the-i...  20241127T201500Z   \n",
       "20999  https://www.chubun.com/modules/article/view.ar...  20241130T093000Z   \n",
       "\n",
       "                                                   title              domain  \n",
       "0      British Columbia Investment Management Corp Cu...  weeklyregister.com  \n",
       "1      Can Apple Inc . ( AAPL ) s Tomorrow be Differe...        bzweekly.com  \n",
       "2      Could Apple Inc . ( AAPL ) Change Direction Af...         kldaily.com  \n",
       "3      Eaton Vance Management Has Trimmed Position in...  friscofastball.com  \n",
       "4      As Apple INC ( AAPL ) Stock Price Rose , Share...    finnewsdaily.com  \n",
       "...                                                  ...                 ...  \n",
       "20995  Apple expands  There more in an iPhone  campai...       telegrafi.com  \n",
       "20996          팀 쿡 애플 CEO  中 , 세계에서 가장 중요한 공급사슬 - Xinhua    kr.xinhuanet.com  \n",
       "20997            मुस्ताङको कृषि उत्पादनमा पर्यटकको क्रेज   annapurnapost.com  \n",
       "20998    The next iPhone SE will be a study in sacrifice        macworld.com  \n",
       "20999                      中文导报网 - 导报新闻 - 苹果总裁库克 年内第三次访华          chubun.com  \n",
       "\n",
       "[21000 rows x 4 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apple_news_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22084c7d-9bc0-4d07-a3cd-45d3e2a8a766",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0ac83d8c-1a5b-4100-897d-7a6c62c58b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# Defining the tickers and company names\n",
    "tickers = ['TSLA', 'AAPL']\n",
    "start_date = '2018-01-01'\n",
    "end_date = '2024-12-01'\n",
    "\n",
    "# Creating a dict to store the data for each company\n",
    "stock_data = {}\n",
    "\n",
    "# Downloading historical data from Yahoo Finance for each ticker\n",
    "for ticker in tickers:\n",
    "    stock_data[ticker] = yf.download(ticker, start=start_date, end=end_date, interval='1d')\n",
    "\n",
    "tesla_data = stock_data['TSLA']\n",
    "apple_data = stock_data['AAPL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cf18215c-33bd-4f15-8ee2-3c71a6088414",
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla_data.reset_index(inplace=True)\n",
    "apple_data.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "76946901-c8eb-4053-a96c-653108ca8e05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>20.799999</td>\n",
       "      <td>21.474001</td>\n",
       "      <td>20.733334</td>\n",
       "      <td>21.368668</td>\n",
       "      <td>21.368668</td>\n",
       "      <td>65283000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>21.400000</td>\n",
       "      <td>21.683332</td>\n",
       "      <td>21.036667</td>\n",
       "      <td>21.150000</td>\n",
       "      <td>21.150000</td>\n",
       "      <td>67822500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>20.858000</td>\n",
       "      <td>21.236668</td>\n",
       "      <td>20.378668</td>\n",
       "      <td>20.974667</td>\n",
       "      <td>20.974667</td>\n",
       "      <td>149194500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>21.108000</td>\n",
       "      <td>21.149332</td>\n",
       "      <td>20.799999</td>\n",
       "      <td>21.105333</td>\n",
       "      <td>21.105333</td>\n",
       "      <td>68868000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-08</td>\n",
       "      <td>21.066668</td>\n",
       "      <td>22.468000</td>\n",
       "      <td>21.033333</td>\n",
       "      <td>22.427334</td>\n",
       "      <td>22.427334</td>\n",
       "      <td>147891000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1735</th>\n",
       "      <td>2024-11-22</td>\n",
       "      <td>341.089996</td>\n",
       "      <td>361.529999</td>\n",
       "      <td>337.700012</td>\n",
       "      <td>352.559998</td>\n",
       "      <td>352.559998</td>\n",
       "      <td>89140700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1736</th>\n",
       "      <td>2024-11-25</td>\n",
       "      <td>360.140015</td>\n",
       "      <td>361.929993</td>\n",
       "      <td>338.200012</td>\n",
       "      <td>338.589996</td>\n",
       "      <td>338.589996</td>\n",
       "      <td>95890900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1737</th>\n",
       "      <td>2024-11-26</td>\n",
       "      <td>341.000000</td>\n",
       "      <td>346.959991</td>\n",
       "      <td>335.660004</td>\n",
       "      <td>338.230011</td>\n",
       "      <td>338.230011</td>\n",
       "      <td>62295900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1738</th>\n",
       "      <td>2024-11-27</td>\n",
       "      <td>341.799988</td>\n",
       "      <td>342.549988</td>\n",
       "      <td>326.589996</td>\n",
       "      <td>332.890015</td>\n",
       "      <td>332.890015</td>\n",
       "      <td>57896400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1739</th>\n",
       "      <td>2024-11-29</td>\n",
       "      <td>336.079987</td>\n",
       "      <td>345.450012</td>\n",
       "      <td>334.649994</td>\n",
       "      <td>345.160004</td>\n",
       "      <td>345.160004</td>\n",
       "      <td>37167600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1740 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date        Open        High         Low       Close   Adj Close  \\\n",
       "0    2018-01-02   20.799999   21.474001   20.733334   21.368668   21.368668   \n",
       "1    2018-01-03   21.400000   21.683332   21.036667   21.150000   21.150000   \n",
       "2    2018-01-04   20.858000   21.236668   20.378668   20.974667   20.974667   \n",
       "3    2018-01-05   21.108000   21.149332   20.799999   21.105333   21.105333   \n",
       "4    2018-01-08   21.066668   22.468000   21.033333   22.427334   22.427334   \n",
       "...         ...         ...         ...         ...         ...         ...   \n",
       "1735 2024-11-22  341.089996  361.529999  337.700012  352.559998  352.559998   \n",
       "1736 2024-11-25  360.140015  361.929993  338.200012  338.589996  338.589996   \n",
       "1737 2024-11-26  341.000000  346.959991  335.660004  338.230011  338.230011   \n",
       "1738 2024-11-27  341.799988  342.549988  326.589996  332.890015  332.890015   \n",
       "1739 2024-11-29  336.079987  345.450012  334.649994  345.160004  345.160004   \n",
       "\n",
       "         Volume  \n",
       "0      65283000  \n",
       "1      67822500  \n",
       "2     149194500  \n",
       "3      68868000  \n",
       "4     147891000  \n",
       "...         ...  \n",
       "1735   89140700  \n",
       "1736   95890900  \n",
       "1737   62295900  \n",
       "1738   57896400  \n",
       "1739   37167600  \n",
       "\n",
       "[1740 rows x 7 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tesla_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "544eeb69-914f-42b6-a443-64ebe0eaaac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>42.540001</td>\n",
       "      <td>43.075001</td>\n",
       "      <td>42.314999</td>\n",
       "      <td>43.064999</td>\n",
       "      <td>40.524345</td>\n",
       "      <td>102223600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>43.132500</td>\n",
       "      <td>43.637501</td>\n",
       "      <td>42.990002</td>\n",
       "      <td>43.057499</td>\n",
       "      <td>40.517288</td>\n",
       "      <td>118071600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>43.134998</td>\n",
       "      <td>43.367500</td>\n",
       "      <td>43.020000</td>\n",
       "      <td>43.257500</td>\n",
       "      <td>40.705486</td>\n",
       "      <td>89738400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>43.360001</td>\n",
       "      <td>43.842499</td>\n",
       "      <td>43.262501</td>\n",
       "      <td>43.750000</td>\n",
       "      <td>41.168930</td>\n",
       "      <td>94640000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-08</td>\n",
       "      <td>43.587502</td>\n",
       "      <td>43.902500</td>\n",
       "      <td>43.482498</td>\n",
       "      <td>43.587502</td>\n",
       "      <td>41.016026</td>\n",
       "      <td>82271200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1735</th>\n",
       "      <td>2024-11-22</td>\n",
       "      <td>228.059998</td>\n",
       "      <td>230.720001</td>\n",
       "      <td>228.059998</td>\n",
       "      <td>229.869995</td>\n",
       "      <td>229.869995</td>\n",
       "      <td>38168300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1736</th>\n",
       "      <td>2024-11-25</td>\n",
       "      <td>231.460007</td>\n",
       "      <td>233.250000</td>\n",
       "      <td>229.740005</td>\n",
       "      <td>232.869995</td>\n",
       "      <td>232.869995</td>\n",
       "      <td>90152800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1737</th>\n",
       "      <td>2024-11-26</td>\n",
       "      <td>233.330002</td>\n",
       "      <td>235.570007</td>\n",
       "      <td>233.330002</td>\n",
       "      <td>235.059998</td>\n",
       "      <td>235.059998</td>\n",
       "      <td>45986200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1738</th>\n",
       "      <td>2024-11-27</td>\n",
       "      <td>234.470001</td>\n",
       "      <td>235.690002</td>\n",
       "      <td>233.809998</td>\n",
       "      <td>234.929993</td>\n",
       "      <td>234.929993</td>\n",
       "      <td>33498400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1739</th>\n",
       "      <td>2024-11-29</td>\n",
       "      <td>234.809998</td>\n",
       "      <td>237.809998</td>\n",
       "      <td>233.970001</td>\n",
       "      <td>237.330002</td>\n",
       "      <td>237.330002</td>\n",
       "      <td>28481400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1740 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date        Open        High         Low       Close   Adj Close  \\\n",
       "0    2018-01-02   42.540001   43.075001   42.314999   43.064999   40.524345   \n",
       "1    2018-01-03   43.132500   43.637501   42.990002   43.057499   40.517288   \n",
       "2    2018-01-04   43.134998   43.367500   43.020000   43.257500   40.705486   \n",
       "3    2018-01-05   43.360001   43.842499   43.262501   43.750000   41.168930   \n",
       "4    2018-01-08   43.587502   43.902500   43.482498   43.587502   41.016026   \n",
       "...         ...         ...         ...         ...         ...         ...   \n",
       "1735 2024-11-22  228.059998  230.720001  228.059998  229.869995  229.869995   \n",
       "1736 2024-11-25  231.460007  233.250000  229.740005  232.869995  232.869995   \n",
       "1737 2024-11-26  233.330002  235.570007  233.330002  235.059998  235.059998   \n",
       "1738 2024-11-27  234.470001  235.690002  233.809998  234.929993  234.929993   \n",
       "1739 2024-11-29  234.809998  237.809998  233.970001  237.330002  237.330002   \n",
       "\n",
       "         Volume  \n",
       "0     102223600  \n",
       "1     118071600  \n",
       "2      89738400  \n",
       "3      94640000  \n",
       "4      82271200  \n",
       "...         ...  \n",
       "1735   38168300  \n",
       "1736   90152800  \n",
       "1737   45986200  \n",
       "1738   33498400  \n",
       "1739   28481400  \n",
       "\n",
       "[1740 rows x 7 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apple_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e31115-0967-4829-a216-c91f39c39b81",
   "metadata": {},
   "source": [
    "##### Saving all the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f5400f20-77d7-43c2-8968-05113fedb4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsla_reddit_data_18_to_24.to_csv(\"tesla_reddit_data_18_to_24.csv\", index=False)\n",
    "aapl_reddit_data_18_to_24.to_csv(\"aapl_reddit_data_18_to_24.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c82284ff-9a0c-46d2-afd3-89803050c911",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsla_news_data.to_csv(\"tesla_news_data_18_to_24.csv\", index=False)\n",
    "apple_news_data.to_csv(\"aapl_news_data_18_to_24.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "395e7c59-40f1-40c3-88e7-48bf14909173",
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla_data.to_csv(\"tesla_stocks_18_to_24.csv\", index=False)\n",
    "apple_data.to_csv(\"aapl_stocks_18_to_24.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0ec0e9-71ba-4c62-9f45-3776674a49b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
